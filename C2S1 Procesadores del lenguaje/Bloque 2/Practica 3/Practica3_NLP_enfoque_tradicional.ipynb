{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "0oFc6yQWgalf"
   },
   "cell_type": "markdown",
   "source": [
    "# NLP - Enfoque tradicional\n",
    "Este notebook cubre varios conceptos del procesamiento del lenguaje natural (NLP) tradicional y utiliza diferentes bibliotecas como NLTK, SpaCy, TextBlob, Gensim y Scikit-learn para implementarlos y visualizarlos.\n"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqRKuoCug2yN",
    "outputId": "f040ecce-4355-4893-d798-e0c6746b7323",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:41:36.516625Z",
     "start_time": "2024-11-21T19:37:38.696681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!conda install -y nltk\n",
    "!conda install -y spacy\n",
    "!conda install -y textblob\n",
    "!conda install -y gensim\n",
    "!conda install -y scikit-learn\n",
    "!conda install -y pyLDAvis\n",
    "!conda install -y conda-forge::language_tool_python"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Soft\\conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    annotated-types-0.6.0      |  py312haa95532_0          26 KB\n",
      "    catalogue-2.0.10           |  py312haa95532_0          42 KB\n",
      "    cloudpathlib-0.16.0        |  py312haa95532_1          86 KB\n",
      "    confection-0.1.4           |  py312hfc267ef_0          89 KB\n",
      "    cymem-2.0.6                |  py312hd77b12b_0          42 KB\n",
      "    cython-blis-1.0.1          |  py312h827c3e9_0         4.7 MB\n",
      "    langcodes-3.3.0            |     pyhd3eb1b0_0         151 KB\n",
      "    markdown-it-py-2.2.0       |  py312haa95532_1         149 KB\n",
      "    mdurl-0.1.0                |  py312haa95532_0          22 KB\n",
      "    murmurhash-1.0.7           |  py312hd77b12b_0          29 KB\n",
      "    numpy-2.0.1                |  py312hfd52020_1          11 KB\n",
      "    numpy-base-2.0.1           |  py312h4dde369_1         7.1 MB\n",
      "    preshed-3.0.6              |  py312h6c2663c_0          89 KB\n",
      "    pydantic-2.8.2             |  py312haa95532_0         780 KB\n",
      "    pydantic-core-2.20.1       |  py312hefb1915_0         1.8 MB\n",
      "    rich-13.7.1                |  py312haa95532_0         619 KB\n",
      "    shellingham-1.5.0          |  py312haa95532_0          21 KB\n",
      "    smart_open-5.2.1           |  py312haa95532_0          94 KB\n",
      "    spacy-3.8.2                |  py312h214f63a_0         6.4 MB\n",
      "    spacy-legacy-3.0.12        |  py312haa95532_0          60 KB\n",
      "    spacy-loggers-1.0.4        |  py312haa95532_0          23 KB\n",
      "    srsly-2.4.8                |  py312hd77b12b_1         669 KB\n",
      "    thinc-8.3.2                |  py312h214f63a_0         1.0 MB\n",
      "    typer-0.9.0                |  py312haa95532_0         105 KB\n",
      "    wasabi-0.9.1               |  py312haa95532_0          49 KB\n",
      "    weasel-0.3.4               |  py312haa95532_0         116 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        24.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  annotated-types    pkgs/main/win-64::annotated-types-0.6.0-py312haa95532_0 \n",
      "  catalogue          pkgs/main/win-64::catalogue-2.0.10-py312haa95532_0 \n",
      "  cloudpathlib       pkgs/main/win-64::cloudpathlib-0.16.0-py312haa95532_1 \n",
      "  confection         pkgs/main/win-64::confection-0.1.4-py312hfc267ef_0 \n",
      "  cymem              pkgs/main/win-64::cymem-2.0.6-py312hd77b12b_0 \n",
      "  cython-blis        pkgs/main/win-64::cython-blis-1.0.1-py312h827c3e9_0 \n",
      "  langcodes          pkgs/main/noarch::langcodes-3.3.0-pyhd3eb1b0_0 \n",
      "  markdown-it-py     pkgs/main/win-64::markdown-it-py-2.2.0-py312haa95532_1 \n",
      "  mdurl              pkgs/main/win-64::mdurl-0.1.0-py312haa95532_0 \n",
      "  murmurhash         pkgs/main/win-64::murmurhash-1.0.7-py312hd77b12b_0 \n",
      "  preshed            pkgs/main/win-64::preshed-3.0.6-py312h6c2663c_0 \n",
      "  pydantic           pkgs/main/win-64::pydantic-2.8.2-py312haa95532_0 \n",
      "  pydantic-core      pkgs/main/win-64::pydantic-core-2.20.1-py312hefb1915_0 \n",
      "  rich               pkgs/main/win-64::rich-13.7.1-py312haa95532_0 \n",
      "  shellingham        pkgs/main/win-64::shellingham-1.5.0-py312haa95532_0 \n",
      "  smart_open         pkgs/main/win-64::smart_open-5.2.1-py312haa95532_0 \n",
      "  spacy              pkgs/main/win-64::spacy-3.8.2-py312h214f63a_0 \n",
      "  spacy-legacy       pkgs/main/win-64::spacy-legacy-3.0.12-py312haa95532_0 \n",
      "  spacy-loggers      pkgs/main/win-64::spacy-loggers-1.0.4-py312haa95532_0 \n",
      "  srsly              pkgs/main/win-64::srsly-2.4.8-py312hd77b12b_1 \n",
      "  thinc              pkgs/main/win-64::thinc-8.3.2-py312h214f63a_0 \n",
      "  typer              pkgs/main/win-64::typer-0.9.0-py312haa95532_0 \n",
      "  wasabi             pkgs/main/win-64::wasabi-0.9.1-py312haa95532_0 \n",
      "  weasel             pkgs/main/win-64::weasel-0.3.4-py312haa95532_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  numpy                               2.1.3-py312hfd52020_0 --> 2.0.1-py312hfd52020_1 \n",
      "  numpy-base                          2.1.3-py312h4dde369_0 --> 2.0.1-py312h4dde369_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "numpy-base-2.0.1     | 7.1 MB    |            |   0% \n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    |            |   0% \u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    |            |   0% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    |            |   0% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-2.8.2       | 780 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rich-13.7.1          | 619 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 151 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "markdown-it-py-2.2.0 | 149 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 116 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typer-0.9.0          | 105 KB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "smart_open-5.2.1     | 94 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.6        | 89 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "confection-0.1.4     | 89 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 86 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 60 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-0.9.1         | 49 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 42 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | 1          |   2% \u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    |            |   0% \n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    |            |   1% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    |            |   0% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    | 1          |   1% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | ##1        |  22% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    | ##1        |  21% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | 7          |   7% \u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | 6          |   7% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    | ##8        |  28% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | #####7     |  57% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    | #####3     |  53% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ##1        |  22% \u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | #5         |  16% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    | #######4   |  75% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ##2        |  23% \n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | ########6  |  87% \u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ###1       |  32% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    | ########8  |  89% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | ########## | 100% \u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ####7      |  48% \u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ###3       |  33% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-2.8.2       | 780 KB    | 2          |   2% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    | 2          |   2% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | #####8     |  59% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rich-13.7.1          | 619 KB    | 2          |   3% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rich-13.7.1          | 619 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ####1      |  41% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-2.8.2       | 780 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-2.8.2       | 780 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    | ######2    |  62% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ########   |  81% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "markdown-it-py-2.2.0 | 149 KB    | #          |  11% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 151 KB    | #          |  11% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "markdown-it-py-2.2.0 | 149 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 151 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | #####8     |  59% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typer-0.9.0          | 105 KB    | #5         |  15% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 116 KB    | #3         |  14% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ########## | 100% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ########## | 100% \u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########   |  80% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "smart_open-5.2.1     | 94 KB     | #7         |  17% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typer-0.9.0          | 105 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 116 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "smart_open-5.2.1     | 94 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.6        | 89 KB     | #7         |  18% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.6        | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 86 KB     | #8         |  19% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 60 KB     | ##6        |  27% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "confection-0.1.4     | 89 KB     | #7         |  18% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 60 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 86 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "confection-0.1.4     | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-0.9.1         | 49 KB     | ###2       |  33% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-0.9.1         | 49 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 42 KB     | ###8       |  38% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 42 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.20.1 | 1.8 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rich-13.7.1          | 619 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rich-13.7.1          | 619 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.3.2          | 1.0 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-2.8.2       | 780 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 151 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 151 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "markdown-it-py-2.2.0 | 149 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "markdown-it-py-2.2.0 | 149 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "cython-blis-1.0.1    | 4.7 MB    | ########## | 100% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typer-0.9.0          | 105 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typer-0.9.0          | 105 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 116 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 116 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 669 KB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "smart_open-5.2.1     | 94 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "smart_open-5.2.1     | 94 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.6        | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.6        | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 60 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 60 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 86 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 86 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "confection-0.1.4     | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "confection-0.1.4     | 89 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-0.9.1         | 49 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-0.9.1         | 49 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 42 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 42 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "spacy-3.8.2          | 6.4 MB    | ########## | 100% \u001B[A\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      \n",
      "\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001B[A\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\u001B[A\n",
      "\n",
      "\n",
      "\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Soft\\conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.18.0.post0      |  py312hfc267ef_0         679 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         679 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           pkgs/main/win-64::textblob-0.18.0.post0-py312hfc267ef_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "textblob-0.18.0.post | 679 KB    |            |   0% \n",
      "textblob-0.18.0.post | 679 KB    | 2          |   2% \n",
      "textblob-0.18.0.post | 679 KB    | ##5        |  26% \n",
      "textblob-0.18.0.post | 679 KB    | #######7   |  78% \n",
      "textblob-0.18.0.post | 679 KB    | ########## | 100% \n",
      "textblob-0.18.0.post | 679 KB    | ########## | 100% \n",
      "                                                     \n",
      " done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Soft\\conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cython-blis-0.7.11         |  py312he558020_0         3.6 MB\n",
      "    gensim-4.3.3               |  py312h0158946_0        42.3 MB\n",
      "    numpy-1.26.4               |  py312hfd52020_0          11 KB\n",
      "    numpy-base-1.26.4          |  py312h4dde369_0         6.6 MB\n",
      "    scipy-1.13.1               |  py312hbb039d4_0        22.5 MB\n",
      "    spacy-3.7.2                |  py312h7595494_0         6.3 MB\n",
      "    thinc-8.2.2                |  py312h82e57e1_0         1.0 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        82.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  gensim             pkgs/main/win-64::gensim-4.3.3-py312h0158946_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  cython-blis                         1.0.1-py312h827c3e9_0 --> 0.7.11-py312he558020_0 \n",
      "  numpy                               2.0.1-py312hfd52020_1 --> 1.26.4-py312hfd52020_0 \n",
      "  numpy-base                          2.0.1-py312h4dde369_1 --> 1.26.4-py312h4dde369_0 \n",
      "  scipy                              1.14.1-py312h9d85e7c_0 --> 1.13.1-py312hbb039d4_0 \n",
      "  spacy                               3.8.2-py312h214f63a_0 --> 3.7.2-py312h7595494_0 \n",
      "  thinc                               8.3.2-py312h214f63a_0 --> 8.2.2-py312h82e57e1_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "gensim-4.3.3         | 42.3 MB   |            |   0% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   |            |   0% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    |            |   0% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    |            |   0% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 11 KB     |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   |            |   0% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   |            |   0% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    |            |   0% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    |            |   0% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    |            |   0% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | 1          |   2% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | 2          |   2% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | 8          |   8% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | 7          |   7% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | ##         |  20% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | 5          |   6% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | 6          |   6% \u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | 3          |   4% \n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | #4         |  14% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | 9          |   9% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | 7          |   8% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | ###8       |  39% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | #2         |  12% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ##3        |  23% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #1         |  11% \n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | #8         |  19% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | ######     |  60% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #4         |  15% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ###1       |  31% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ##4        |  24% \u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #4         |  14% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | #######6   |  76% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #8         |  18% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ####       |  41% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ##3        |  23% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #8         |  19% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | #########8 |  98% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ###2       |  32% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ####8      |  49% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ##1        |  22% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ##7        |  27% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ###8       |  39% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | 1          |   2% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ##5        |  25% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ########4  |  85% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | #####6     |  56% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ###        |  31% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ####4      |  45% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 11 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 11 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ##9        |  30% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ###5       |  36% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | #####2     |  53% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ######6    |  66% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.11   | 3.6 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 11 KB     | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ###3       |  34% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ####1      |  41% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ######2    |  63% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | #######7   |  78% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ###8       |  39% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ####6      |  46% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | #######    |  71% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ########6  |  87% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ####2      |  43% \n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ########   |  80% \u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #####1     |  51% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | #########7 |  97% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ####8      |  49% \n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #####6     |  57% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | #########1 |  92% \u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #####3     |  53% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ######2    |  62% \u001B[A\n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ########## | 100% \u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #####9     |  59% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ######8    |  69% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ######4    |  65% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #######5   |  76% \u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ########3  |  83% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | #######1   |  72% \n",
      "gensim-4.3.3         | 42.3 MB   | #######7   |  78% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | #########  |  91% \u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ########3  |  84% \n",
      "gensim-4.3.3         | 42.3 MB   | #########2 |  92% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ########## | 100% \u001B[A\n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ########## | 100% \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ########## | 100% \n",
      "gensim-4.3.3         | 42.3 MB   | ########## | 100% \n",
      "\n",
      "\n",
      "numpy-base-1.26.4    | 6.6 MB    | ########## | 100% \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "spacy-3.7.2          | 6.3 MB    | ########## | 100% \u001B[A\u001B[A\u001B[A\n",
      "gensim-4.3.3         | 42.3 MB   | ########## | 100% \n",
      "\n",
      "scipy-1.13.1         | 22.5 MB   | ########## | 100% \u001B[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001B[A\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Soft\\conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    scikit-learn-1.5.1         |  py312h0158946_0         9.3 MB\n",
      "    threadpoolctl-3.5.0        |  py312hfc267ef_0          49 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  scikit-learn       pkgs/main/win-64::scikit-learn-1.5.1-py312h0158946_0 \n",
      "  threadpoolctl      pkgs/main/win-64::threadpoolctl-3.5.0-py312hfc267ef_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "scikit-learn-1.5.1   | 9.3 MB    |            |   0% \n",
      "\n",
      "threadpoolctl-3.5.0  | 49 KB     |            |   0% \u001B[A\n",
      "\n",
      "threadpoolctl-3.5.0  | 49 KB     | ########## | 100% \u001B[A\n",
      "scikit-learn-1.5.1   | 9.3 MB    | 5          |   5% \n",
      "\n",
      "threadpoolctl-3.5.0  | 49 KB     | ########## | 100% \u001B[A\n",
      "\n",
      "threadpoolctl-3.5.0  | 49 KB     | ########## | 100% \u001B[A\n",
      "scikit-learn-1.5.1   | 9.3 MB    | ###9       |  40% \n",
      "scikit-learn-1.5.1   | 9.3 MB    | ######2    |  62% \n",
      "scikit-learn-1.5.1   | 9.3 MB    | ########## | 100% \n",
      "scikit-learn-1.5.1   | 9.3 MB    | ########## | 100% \n",
      "scikit-learn-1.5.1   | 9.3 MB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001B[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - pyldavis\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main\n",
      "  - https://repo.anaconda.com/pkgs/r\n",
      "  - https://repo.anaconda.com/pkgs/msys2\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - language_tool_python\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main\n",
      "  - https://repo.anaconda.com/pkgs/r\n",
      "  - https://repo.anaconda.com/pkgs/msys2\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "TcKGlXc1gali"
   },
   "cell_type": "markdown",
   "source": [
    "## 1. Tokenizacin y Etiquetado POS (Anlisis Lxico y Sintctico - NLTK y SpaCy)\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teora:**\\\n",
    "La **tokenizacin** es el proceso de dividir un texto en unidades ms pequeas llamadas \"tokens\". Esto es importante porque la mayora de las tareas de NLP necesitan trabajar con palabras individuales o grupos pequeos de palabras.\\\n",
    "El **etiquetado POS (Part-of-Speech)** clasifica cada palabra en su categora gramatical (como sustantivo, verbo, adjetivo, etc.), lo cual es crucial para entender la estructura gramatical de una oracin."
   ],
   "metadata": {
    "id": "8uKuoxgKhtAZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacin con NLTK**\n",
    "\n"
   ],
   "metadata": {
    "id": "TKH5ACm4hxlZ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH6qsGw2galk",
    "outputId": "e0886ab6-b64e-490e-80a2-a1fdad378d9b",
    "ExecuteTime": {
     "end_time": "2024-11-21T19:29:28.001806Z",
     "start_time": "2024-11-21T19:29:27.713875Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Ejemplo de texto en ingls\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenizacin - Lxico\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Etiquetado POS con NLTK - Sintctico\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"Etiquetas POS:\", pos_tags)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\imarc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\imarc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\imarc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "Etiquetas POS: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge8Tt91Tgalm"
   },
   "source": [
    "**Visualizacin con Spacy**\\\n",
    "SpaCy proporciona una representacin visual interactiva del **rbol de dependencias**, mostrando las **relaciones gramaticales** y las **etiquetas POS** *texto en cursiva*, lo que facilita la comprensin de la estructura de la oracin."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''Necesitamos el modelo en espaol porque cada idioma tiene su propia estructura gramatical y reglas sintcticas.\n",
    "   Un modelo preentrenado en espaol como el de SpaCy puede realizar estas tareas de etiquetado gramatical y anlisis sintctico con precisin,\n",
    "   porque ha sido entrenado en los patrones lingsticos especficos de este idioma.'''\n",
    "!conda install -y spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "#descarga el modelo espaol de spacy (terminal)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "r5Gb4IwFjm0E",
    "outputId": "18fd6273-739e-4f79-8094-d089dc6fd449",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:23:15.226809Z",
     "start_time": "2024-11-21T20:22:26.957523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "yycE3iEEgalm",
    "outputId": "b80b7f30-7003-4f2d-f98f-5fa9444d515e",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:27:12.860943Z",
     "start_time": "2024-11-21T20:27:09.439022Z"
    }
   },
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Cargar el modelo en espaol\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = 'The quick brown fox jumps over the lazy dog.'\n",
    "\n",
    "# Procesar el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualizar el rbol de dependencias, incluyendo etiquetas POS.\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"520ed210b2224b0a8671ec633c1b1a37-0\" class=\"displacy\" width=\"950\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,2.0 350.0,2.0 350.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,52.0 345.0,52.0 345.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,154.0 L262,142.0 278,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-4\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M540.0,154.0 L548.0,142.0 532.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,52.0 845.0,52.0 845.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-6\" stroke-width=\"2px\" d=\"M770,152.0 C770,102.0 840.0,102.0 840.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,154.0 L762,142.0 778,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-520ed210b2224b0a8671ec633c1b1a37-0-7\" stroke-width=\"2px\" d=\"M570,152.0 C570,2.0 850.0,2.0 850.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-520ed210b2224b0a8671ec633c1b1a37-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M850.0,154.0 L858.0,142.0 842.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk4PTycYgaln"
   },
   "source": [
    "## 2. Lematizacin y Reconocimiento de Entidades Nombradas (NER) (Anlisis Lxico y Semntico - SpaCy)\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teora:**\\\n",
    "La **lematizacin** reduce una palabra a su forma base o lema, ayudando a agrupar palabras con el mismo significado pero diferentes formas morfolgicas.\\\n",
    "El **Reconocimiento de Entidades Nombradas (NER)** identifica entidades clave en el texto, como personas, lugares, organizaciones, etc., y es til para extraer informacin relevante automticamente."
   ],
   "metadata": {
    "id": "esWHgj3vlM6J"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacin y visualizacin con SpaCy.**"
   ],
   "metadata": {
    "id": "aoc9uAc3lPIT"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHUcLBYagaln",
    "outputId": "63532d06-ebe5-4539-ecf0-12a86c7b4414",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:27:38.306314Z",
     "start_time": "2024-11-21T20:27:31.088020Z"
    }
   },
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "!python -m spacy download es_core_news_sm\n",
    "# Cargar modelo en espaol\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = 'Apple fue fundada por Steve Jobs en California.'\n",
    "\n",
    "# Procesar el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lematizacin - Lxico\n",
    "print('Lemas:')\n",
    "for token in doc:\n",
    "    print(f'{token.text} -> {token.lemma_}')\n",
    "\n",
    "# Visualizacin de Entidades Nombradas - lxico/semntico\n",
    "displacy.render(doc, style='ent', jupyter=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     ---------------------------- ----------- 9.2/12.9 MB 47.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 38.5 MB/s eta 0:00:00\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Lemas:\n",
      "Apple -> Apple\n",
      "fue -> ser\n",
      "fundada -> fundar\n",
      "por -> por\n",
      "Steve -> Steve\n",
      "Jobs -> Jobs\n",
      "en -> en\n",
      "California -> California\n",
      ". -> .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " fue fundada por \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " en \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "IuINyxEYlnq5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "CywoznsRsV4z"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJAX3owwlvQ-"
   },
   "source": [
    "## 3. Anlisis de Sentimiento y Correccin Gramatical (Anlisis Semntico - TextBlob)\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teora:**\\\n",
    "El **anlisis de sentimiento** mide la polaridad del texto (positivo, negativo, neutral) y es til para comprender la opinin o actitud expresada en grandes volmenes de texto.\\\n",
    "La **correccin gramatical** asegura la claridad y precisin del texto, especialmente en aplicaciones de escritura asistida."
   ],
   "metadata": {
    "id": "XFdhcGddl6m6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacin con TextBlob. - Analisis de sentimiento**"
   ],
   "metadata": {
    "id": "00NQB7M_l62A"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QSDCvxH9lvRA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "fb3016aa-f6f3-4ac5-a22c-27f54cb2901c",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:28:23.709258Z",
     "start_time": "2024-11-21T20:28:19.129092Z"
    }
   },
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Example text\n",
    "text = 'This product is absolutely wonderful.'\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentiment = blob.sentiment\n",
    "print(f'Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}')\n",
    "'''\n",
    "La frase tiene un sentimiento extremadamente positivo,\n",
    "por lo que la polaridad debera estar cerca de 1.0.\n",
    "Dado que la frase expresa una opinin subjetiva sobre el producto,\n",
    "la subjetividad tambin debera ser alta, cerca de 1.0\n",
    "'''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity: 1.0, Subjectivity: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLa frase tiene un sentimiento extremadamente positivo,\\npor lo que la polaridad debera estar cerca de 1.0.\\nDado que la frase expresa una opinin subjetiva sobre el producto,\\nla subjetividad tambin debera ser alta, cerca de 1.0\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacin con Language Tool. - Correccin gramatical**"
   ],
   "metadata": {
    "id": "8-Q5RKPgr6cp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!conda install language_tool_python\n",
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "text_with_errors = \"She go to the market and buy apples.\"\n",
    "\n",
    "# Aplicar la correccin\n",
    "matches = tool.check(text_with_errors)\n",
    "corrected_text = language_tool_python.utils.correct(text_with_errors, matches)\n",
    "\n",
    "print(\"Original text:\", text_with_errors)\n",
    "print(\"Corrected text:\", corrected_text)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2v3H6STnvnP",
    "outputId": "1228031e-9c22-4305-e20d-441854e7fd2f",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:29:19.932614Z",
     "start_time": "2024-11-21T20:28:50.885381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|| 246M/246M [00:06<00:00, 37.1MB/s] \n",
      "Unzipping C:\\Users\\imarc\\AppData\\Local\\Temp\\tmpz16d64ka.zip to C:\\Users\\imarc\\.cache\\language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to C:\\Users\\imarc\\.cache\\language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: She go to the market and buy apples.\n",
      "Corrected text: She goes to the market and buy apples.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Bolsa de Palabras (BoW) y TF-IDF (Anlisis Lxico - Gensim y Scikit-learn)\n",
    "----------------"
   ],
   "metadata": {
    "id": "zos_Hqp0sohD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teora:**\\\n",
    "La **Bolsa de Palabras (BoW)** representa un documento como un vector de frecuencias de palabras, ignorando el orden.\\\n",
    "El **TF-IDF** pondera la importancia de una palabra en un documento en relacin con el conjunto de documentos, destacando palabras relevantes mientras se penalizan las comunes."
   ],
   "metadata": {
    "id": "PxaNA1xzsu1x"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacion con Gensim - BoW**"
   ],
   "metadata": {
    "id": "TmGH1o_Gs_dS"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:32:50.662014Z",
     "start_time": "2024-11-21T20:30:20.345588Z"
    }
   },
   "cell_type": "code",
   "source": "!conda install -y gensim;",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Soft\\conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  gensim             pkgs/main/win-64::gensim-4.3.3-py312h0158946_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  cython-blis                         1.0.1-py312h827c3e9_0 --> 0.7.11-py312he558020_0 \n",
      "  numpy                               2.0.1-py312hfd52020_1 --> 1.26.4-py312hfd52020_0 \n",
      "  numpy-base                          2.0.1-py312h4dde369_1 --> 1.26.4-py312h4dde369_0 \n",
      "  scipy                              1.14.1-py312h9d85e7c_0 --> 1.13.1-py312hbb039d4_0 \n",
      "  spacy                               3.8.2-py312h214f63a_0 --> 3.7.2-py312h7595494_0 \n",
      "  thinc                               8.3.2-py312h214f63a_0 --> 8.2.2-py312h82e57e1_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Gensim para Bolsa de Palabras (BoW)\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Documentos de ejemplo\n",
    "documents = ['El gato negro salt sobre el sof.', 'El perro ladr fuertemente en la casa.']\n",
    "\n",
    "# Tokenizacin\n",
    "texts = [[word.lower() for word in document.split()] for document in documents]\n",
    "\n",
    "# Creacin del diccionario\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(\"Diccionario:\", dictionary.token2id)\n",
    "\n",
    "#Creacin de la bolsa de palabras\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "print('Bolsa de Palabras:', corpus_bow)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z41ZO_oGtABS",
    "outputId": "5e48a711-9f45-4335-8001-806e88bda492",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:40:39.371433Z",
     "start_time": "2024-11-21T20:40:37.638946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario: {'el': 0, 'gato': 1, 'negro': 2, 'salt': 3, 'sobre': 4, 'sof.': 5, 'casa.': 6, 'en': 7, 'fuertemente': 8, 'la': 9, 'ladr': 10, 'perro': 11}\n",
      "Bolsa de Palabras: [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(0, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "El diccionario representa el indice asignado a cada palabra.\\\n",
    "En la Bolsa de Palabras, tenemos un array por cada documento (frase en este caso). Cada array contiene una tupla (pares) por cada palabra. El primer numero de la tupla indica el indice de la palabra, el segundo cuantas veces se repite **en ese mismo** documento.\\\n",
    "\\\n",
    "Una representacin ms grafica de la bolsa de palabras:"
   ],
   "metadata": {
    "id": "yIpworsj763c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Convertir corpus_bow a una representacin ms visual utilizando pandas DataFrame\n",
    "# Creamos una matriz donde las columnas sern las palabras y las filas sern los documentos\n",
    "import pandas as pd\n",
    "data = []\n",
    "\n",
    "for bow in corpus_bow:\n",
    "    bow_dict = dict(bow)\n",
    "    data.append([bow_dict.get(dictionary.token2id[word], 0) for word in dictionary.token2id])\n",
    "\n",
    "# Crear un DataFrame con las palabras como columnas y \"doc 1\", \"doc 2\" como ndices\n",
    "doc_names = [f\"doc {i+1}\" for i in range(len(corpus_bow))]\n",
    "df_bow = pd.DataFrame(data, columns=[dictionary[id] for id in range(len(dictionary))], index=doc_names)\n",
    "\n",
    "# Estilo de la tabla con lneas delimitadoras\n",
    "styled_df_bow = df_bow.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('border', '1px solid black')]},\n",
    "     {'selector': 'td', 'props': [('border', '1px solid black')]}]\n",
    ").set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Mostrar la tabla estilizada\n",
    "styled_df_bow"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "AOwUsSZCtFYl",
    "outputId": "f263d60b-9e51-4049-a300-347926736e5d",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:40:49.726634Z",
     "start_time": "2024-11-21T20:40:49.043936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20415b8aea0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ec6f th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_3ec6f td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_3ec6f_row0_col0, #T_3ec6f_row0_col1, #T_3ec6f_row0_col2, #T_3ec6f_row0_col3, #T_3ec6f_row0_col4, #T_3ec6f_row0_col5, #T_3ec6f_row0_col6, #T_3ec6f_row0_col7, #T_3ec6f_row0_col8, #T_3ec6f_row0_col9, #T_3ec6f_row0_col10, #T_3ec6f_row0_col11, #T_3ec6f_row1_col0, #T_3ec6f_row1_col1, #T_3ec6f_row1_col2, #T_3ec6f_row1_col3, #T_3ec6f_row1_col4, #T_3ec6f_row1_col5, #T_3ec6f_row1_col6, #T_3ec6f_row1_col7, #T_3ec6f_row1_col8, #T_3ec6f_row1_col9, #T_3ec6f_row1_col10, #T_3ec6f_row1_col11 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ec6f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ec6f_level0_col0\" class=\"col_heading level0 col0\" >el</th>\n",
       "      <th id=\"T_3ec6f_level0_col1\" class=\"col_heading level0 col1\" >gato</th>\n",
       "      <th id=\"T_3ec6f_level0_col2\" class=\"col_heading level0 col2\" >negro</th>\n",
       "      <th id=\"T_3ec6f_level0_col3\" class=\"col_heading level0 col3\" >salt</th>\n",
       "      <th id=\"T_3ec6f_level0_col4\" class=\"col_heading level0 col4\" >sobre</th>\n",
       "      <th id=\"T_3ec6f_level0_col5\" class=\"col_heading level0 col5\" >sof.</th>\n",
       "      <th id=\"T_3ec6f_level0_col6\" class=\"col_heading level0 col6\" >casa.</th>\n",
       "      <th id=\"T_3ec6f_level0_col7\" class=\"col_heading level0 col7\" >en</th>\n",
       "      <th id=\"T_3ec6f_level0_col8\" class=\"col_heading level0 col8\" >fuertemente</th>\n",
       "      <th id=\"T_3ec6f_level0_col9\" class=\"col_heading level0 col9\" >la</th>\n",
       "      <th id=\"T_3ec6f_level0_col10\" class=\"col_heading level0 col10\" >ladr</th>\n",
       "      <th id=\"T_3ec6f_level0_col11\" class=\"col_heading level0 col11\" >perro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec6f_level0_row0\" class=\"row_heading level0 row0\" >doc 1</th>\n",
       "      <td id=\"T_3ec6f_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_3ec6f_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_3ec6f_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_3ec6f_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_3ec6f_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_3ec6f_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_3ec6f_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_3ec6f_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_3ec6f_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_3ec6f_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_3ec6f_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_3ec6f_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec6f_level0_row1\" class=\"row_heading level0 row1\" >doc 2</th>\n",
       "      <td id=\"T_3ec6f_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_3ec6f_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_3ec6f_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_3ec6f_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_3ec6f_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_3ec6f_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col10\" class=\"data row1 col10\" >1</td>\n",
       "      <td id=\"T_3ec6f_row1_col11\" class=\"data row1 col11\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacion con Scikit-learn - TF-IDF**"
   ],
   "metadata": {
    "id": "1gIF5U10-P_H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Frecuencia de Trmino (TF):** Mide cuntas veces aparece una palabra especfica en **un** documento.\n",
    "\n",
    "**Frecuencia Inversa de Documentos (IDF):** Mide la rareza de una palabra en el conjunto de documentos. Si una palabra aparece en muchos documentos, su IDF ser **baja**, porque es **menos informativa** (palabras comunes como \"el\", \"y\", \"es\").\\\n",
    "**La ponderacin TF-IDF**: se calcula multiplicando la TF de la palabra por su IDF. Esto pondera la frecuencia de la palabra segn su rareza en el conjunto de documentos.\n",
    "\\\n",
    "**Casos de uso:** Clasificacin de Textos, Bsqueda de Informacin, Filtrado de Palabras Relevantes"
   ],
   "metadata": {
    "id": "CC3crcJt_DZz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Scikit-learn para TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "documents = [\n",
    "    \"El gato negro salt sobre el sof. Luego, el gato descans cmodamente en su lugar favorito. El gato siempre salta con agilidad.\",\n",
    "    \"El perro ladr fuertemente en la casa. Despus, el perro sali a jugar en el jardn. El perro corre rpidamente.\",\n",
    "    \"El gato caz un ratn en el jardn. Los gatos son excelentes cazadores, siempre al acecho. El gato volvi al sof.\",\n",
    "    \"El perro dorma plcidamente en su cama. Cuando el perro se despert, sali corriendo hacia el parque. El perro ama los paseos.\",\n",
    "    \"Los gatos son animales muy independientes. Les gusta dormir durante el da y cazar por la noche. El gato siempre vuelve a casa.\",\n",
    "    \"El perro es conocido por su lealtad hacia los humanos. El perro cuida la casa y siempre est alerta ante cualquier ruido extrao.\",\n",
    "    \"El gato se subi al rbol para escapar del perro. Los gatos son conocidos por su capacidad de trepar y escapar del peligro.\",\n",
    "    \"La computadora se apag repentinamente mientras estaba ejecutando un programa importante. Despus de reiniciarla, todos los archivos volvieron a estar accesibles.\"\n",
    "]\n",
    "\n",
    "# Crear y ajustar el vectorizador TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
    "\n",
    "# Obtener los nombres de las palabras (vocabulario)\n",
    "feature_names = vectorizer_tfidf.get_feature_names_out()\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame de pandas\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "\n",
    "# Aadir nombres de documentos (opcional)\n",
    "df_tfidf.index = [\n",
    "    '1 (gatos)',\n",
    "    '2 (perros)',\n",
    "    '3 (gatos)',\n",
    "    '4 (perros)',\n",
    "    '5 (gatos)',\n",
    "    '6 (perros)',\n",
    "    '7 (gatos)',\n",
    "    '8 (computadoras)'\n",
    "]\n",
    "# Mostrar la tabla\n",
    "print(df_tfidf)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrGWRG_Mvdac",
    "outputId": "24294e70-ec39-4e00-ff9c-46baaa7ea0a0",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:40:56.044880Z",
     "start_time": "2024-11-21T20:40:55.847693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  accesibles    acecho  agilidad        al   alerta       ama  \\\n",
      "1 (gatos)           0.000000  0.000000  0.225216  0.000000  0.00000  0.000000   \n",
      "2 (perros)          0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
      "3 (gatos)           0.000000  0.246797  0.000000  0.413670  0.00000  0.000000   \n",
      "4 (perros)          0.000000  0.000000  0.000000  0.000000  0.00000  0.230705   \n",
      "5 (gatos)           0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
      "6 (perros)          0.000000  0.000000  0.000000  0.000000  0.24537  0.000000   \n",
      "7 (gatos)           0.000000  0.000000  0.000000  0.186692  0.00000  0.000000   \n",
      "8 (computadoras)    0.240549  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
      "\n",
      "                  animales     ante     apag  archivos  ...       son  \\\n",
      "1 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
      "2 (perros)         0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
      "3 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.178482   \n",
      "4 (perros)         0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
      "5 (gatos)          0.25528  0.00000  0.000000  0.000000  ...  0.184617   \n",
      "6 (perros)         0.00000  0.24537  0.000000  0.000000  ...  0.000000   \n",
      "7 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.161100   \n",
      "8 (computadoras)   0.00000  0.00000  0.240549  0.240549  ...  0.000000   \n",
      "\n",
      "                        su     subi     todos    trepar        un  volvieron  \\\n",
      "1 (gatos)         0.142805  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "2 (perros)        0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "3 (gatos)         0.000000  0.000000  0.000000  0.000000  0.206835   0.000000   \n",
      "4 (perros)        0.146285  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "5 (gatos)         0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "6 (perros)        0.155584  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "7 (gatos)         0.141249  0.222762  0.000000  0.222762  0.000000   0.000000   \n",
      "8 (computadoras)  0.000000  0.000000  0.240549  0.000000  0.201599   0.240549   \n",
      "\n",
      "                    volvi   vuelve     rbol  \n",
      "1 (gatos)         0.000000  0.00000  0.000000  \n",
      "2 (perros)        0.000000  0.00000  0.000000  \n",
      "3 (gatos)         0.246797  0.00000  0.000000  \n",
      "4 (perros)        0.000000  0.00000  0.000000  \n",
      "5 (gatos)         0.000000  0.25528  0.000000  \n",
      "6 (perros)        0.000000  0.00000  0.000000  \n",
      "7 (gatos)         0.000000  0.00000  0.222762  \n",
      "8 (computadoras)  0.000000  0.00000  0.000000  \n",
      "\n",
      "[8 rows x 97 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ejemplo de motor de bsqueda\n",
    "**Consulta:** El usuario ingresa una consulta, en este caso \"gato sof\".\\\n",
    "**Transformacin:** La consulta se transforma en su vector TF-IDF utilizando el mismo vectorizador que ya entrenaste con los documentos.\n",
    "**Similitud de Coseno:** Calculamos la similitud de coseno entre el vector TF-IDF de la consulta y los vectores de TF-IDF de los documentos.\\\n",
    "* Similitud de Coseno: mide cun similares son dos vectores (en este caso, el vector de la consulta y los vectores de los documentos).\\\n",
    "* El valor vara entre 0 y 1, donde 1 significa documentos idnticos.\\\n",
    "\n",
    "**Resultado:** Mostramos las similitudes de coseno para cada documento y resaltamos cul es el ms relevante."
   ],
   "metadata": {
    "id": "W3b9IFC1FVsR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tu consulta\n",
    "query = \"gato sof\"\n",
    "\n",
    "# Normalizar la consulta usando el mismo vectorizador TF-IDF que ya has creado\n",
    "query_tfidf = vectorizer_tfidf.transform([query])\n",
    "\n",
    "# Calcular la similitud de coseno entre la consulta y cada documento\n",
    "cosine_similarities = cosine_similarity(query_tfidf, X_tfidf).flatten()\n",
    "\n",
    "# Mostrar las similitudes\n",
    "print(\"Similitud de coseno entre la consulta y los documentos:\")\n",
    "for idx, sim in enumerate(cosine_similarities):\n",
    "    print(f\"Documento {idx + 1}: {sim}\")\n",
    "\n",
    "# Encontrar el documento ms relevante\n",
    "most_similar_doc_index = np.argmax(cosine_similarities)\n",
    "print(f\"\\nEl documento ms relevante para la consulta '{query}' es el Documento {most_similar_doc_index + 1}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LxjktLqA47c",
    "outputId": "9eabaf7a-503a-40dc-8d9c-6aa1029a16f4",
    "ExecuteTime": {
     "end_time": "2024-11-21T20:41:01.562467Z",
     "start_time": "2024-11-21T20:41:01.489946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud de coseno entre la consulta y los documentos:\n",
      "Documento 1: 0.4090089090150796\n",
      "Documento 2: 0.0\n",
      "Documento 3: 0.3537824405001258\n",
      "Documento 4: 0.0\n",
      "Documento 5: 0.09766441205287543\n",
      "Documento 6: 0.0\n",
      "Documento 7: 0.08522379566333722\n",
      "Documento 8: 0.0\n",
      "\n",
      "El documento ms relevante para la consulta 'gato sof' es el Documento 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Practica"
   ],
   "metadata": {
    "id": "B_nUR2B1G1nT"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ejercicio: Exploracin de la Normalizacin en Distintas Libreras\n",
    "\n",
    "### Introduccin:\n",
    "\n",
    "La normalizacin del texto es un paso esencial en el procesamiento del lenguaje natural (NLP) que asegura que el texto est limpio y estructurado para que pueda ser procesado por los algoritmos de NLP. En este ejercicio, aprenders a aplicar diferentes tcnicas de normalizacin del texto utilizando las libreras que hemos visto hasta ahora: **NLTK**, **SpaCy**, **TextBlob**, y **Gensim**.\n",
    "\n",
    "### Tcnicas de Normalizacin:\n",
    "\n",
    "1. **Lowercasing**: Convertir todo el texto a minsculas.\n",
    "2. **Eliminar puntuacin**: Eliminar signos de puntuacin innecesarios.\n",
    "3. **Eliminar nmeros**: Remover los nmeros que no aporten valor al anlisis.\n",
    "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan informacin.\n",
    "5. **Lematizacin**: Reducir las palabras a su forma base.\n",
    "6. **Stemming (opcional)**: Aplicar stemming si la librera lo soporta.\n",
    "7. **Correccin ortogrfica**: Corregir errores ortogrficos en el texto.\n",
    "8. **Tokenizacin**: Dividir el texto en tokens.\n",
    "\n",
    "### Instrucciones:\n",
    "\n",
    "1. Busca en la documentacin de cada librera (NLTK, SpaCy, TextBlob, Gensim) cmo puedes aplicar estas tcnicas de normalizacin.\n",
    "2. Implementa las soluciones que encuentres para normalizar el texto en cada librera.\n",
    "3. Compara los resultados obtenidos en cada una:\n",
    " - Qu diferencias encuentras entre las libreras?Cules son las fortalezas y limitaciones de cada una?\n",
    " - Cmo afect la normalizacin los resultados obtenidos en las diferentes tcnicas de NLP (BoW, anlisis de sentimiento, POS tagging, etc.)?\n",
    "4. Documenta lo implementado en cada tcnica, el output que refleje los cambios y una comparativa antes y despus del cambio.\n",
    "\n",
    "### Recursos:\n",
    "\n",
    "Aqu tienes enlaces a la documentacin de cada librera para comenzar tu investigacin:\n",
    "\n",
    "- [NLTK Documentation](https://www.nltk.org/)\n",
    "- [SpaCy Documentation](https://spacy.io/usage)\n",
    "- [TextBlob Documentation](https://textblob.readthedocs.io/en/dev/)\n",
    "- [Gensim Documentation](https://radimrehurek.com/gensim/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ]
}
