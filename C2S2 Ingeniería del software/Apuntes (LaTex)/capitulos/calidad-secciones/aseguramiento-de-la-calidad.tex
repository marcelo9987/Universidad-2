\begin{definicion}
    Según la norma ISO/IEC 9126, la calidad de un producto software se puede evaluar mediante seis atributos principales:
\end{definicion}

\begin{enumerate}
    \item \textbf{Funcionalidad:} Grado en que el software cumple los requisitos funcionales esperados.
    \item \textbf{Confiabilidad:} Estabilidad del software ante fallos, por ejemplo, el tiempo medio de funcionamiento antes de un fallo.
    \item \textbf{Usabilidad:} Facilidad de uso para los usuarios.
    \item \textbf{Eficiencia:} Uso óptimo de los recursos disponibles (CPU, memoria, etc.).
    \item \textbf{Mantenibilidad:} Facilidad para modificar, corregir o mejorar el software.
    \item \textbf{Portabilidad:} Facilidad para trasladar el software entre diferentes entornos.
\end{enumerate}

\begin{nota}
    Existe un dilema clásico entre producir software rápido y barato o producir software de alta calidad, ya que la calidad requiere tiempo y recursos.
\end{nota}

\begin{nota}
    Los errores pequeños no detectados a tiempo pueden amplificarse y causar problemas mayores en fases posteriores, por lo que la detección temprana es fundamental.
\end{nota}

\subsection{Principios rectores de la calidad}\label{subsec:principios-rectores-de-la-calidad}
\begin{itemize}
    \item \textbf{Formulación.} La derivación de medidas y métricas de software apropiadas
    \item para la representación del software que se está construyendo.
    \item \textbf{Recolección. }Mecanismo que se usa para acumular datos requeridos para derivar las métricas formuladas.
    \item \textbf{Análisis.} El cálculo de métricas y la aplicación de herramientas
    \item matemáticas.
    \item \textbf{Interpretación.} Evaluación de las métricas resultantes para comprender la calidad de la representación.
    \item \textbf{Retroalimentación.} Recomendaciones derivadas de la interpretación de las métricas del producto, transmitidas al equipo de software.
\end{itemize}

\subsection{Atributos de las métricas}\label{subsec:atributos-de-las-metricas}
\begin{enumerate}
    \item \textbf{Medible. }Debe ser simple poder recolectar los datos que componen la métrica y realizar su cálculo.
    \item \textbf{Intuitiva.} Los usuarios de la métrica deben poder identificar su significado y su valor.
    \item \textbf{Objetiva.} Siempre debe producir resultados que no tengan ambigüedades.
    \item \textbf{Coherente.} El cálculo matemático de la métrica debe usar medidas que no conduzcan a combinaciones extrañas de unidades.
    \item \textbf{Tecnológicamente agnóstica.} Debe basarse en el modelo de requerimientos, el modelo de diseño o la estructura del programa en sí.
    \item \textbf{Accionable.} Debe proporcionar información que pueda conducir a un producto final de mayor calidad.
\end{enumerate}

\subsection{Control vs. Aseguramiento de la Calidad}\label{subsec:control-vs.-aseguramiento-de-la-calidad}

\begin{center}
    \begin{tabularx}{\textwidth}{|X|X|}
        \hline
        \textbf{Control de Calidad (QC)}                         & \textbf{Aseguramiento de Calidad (QA)}               \\
        \hline
        Reactivo                                                 & Proactivo                                            \\
        Detección y corrección de errores después de que ocurren & Prevención de errores mediante estándares y procesos \\
        Inspección de productos                                  & Mejora continua de procesos                          \\
        \hline
    \end{tabularx}
\end{center}

\subsection{Revisiones técnicas}\label{subsec:revisiones-tecnicas}

\begin{itemize}
    \item \textbf{Informales:} Conversaciones espontáneas, revisiones en escritorio; baja eficacia que mejora con listas de verificación.
    \item \textbf{Formales:} Reuniones estructuradas y preparadas; alta eficacia, más tiene un alto coste en tiempo y esfuerzo; se utiliza normalmente una muestra representativa.
\end{itemize}

\subsection{Revisiones durante el desarrollo}\label{subsec:revisiones-durante-el-desarrollo}

\begin{itemize}
    \item \textbf{Revisión de código:} Entre compañeros (pair review) para detectar errores y mejorar el aprendizaje del equipo.
    \item \textbf{Análisis estático de código:} Herramientas automáticas que detectan errores potenciales, complejidad y duplicaciones.
\end{itemize}

\subsection{Métricas de calidad (DORA Metrics)}\label{subsec:metricas-de-calidad-(dora-metrics)}

\begin{center}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Métrica}                  & \textbf{Significado}                                 \\
        \hline
        MTTR (Mean Time to Recover)       & Tiempo medio para recuperar un sistema tras un fallo \\
        MTBF (Mean Time Between Failures) & Tiempo medio entre fallos                            \\
        Disponibilidad                    & Proporción de tiempo que el sistema está disponible  \\
        \hline
    \end{tabular}
\end{center}

\begin{definicion}
    La disponibilidad se calcula con la fórmula:
    \[
        \text{Disponibilidad} = \frac{\text{MTBF}}{\text{MTBF} + \text{MTTR}} \cdot 100\%
    \]
\end{definicion}

\subsection{Buenas prácticas de desarrollo}\label{subsec:buenas-practicas-de-desarrollo}

\begin{itemize}
    \item \textbf{Clean Code} (Robert C. Martin - Uncle Bob):
    \begin{itemize}
        \item KISS: “Keep It Simple, Stupid”
        \item DRY: “Don’t Repeat Yourself”
        \item YAGNI: “You Aren’t Gonna Need It”
        \item SoC: “Separation of Concerns”
    \end{itemize}
    \item \textbf{Documentación:} Comentarios explicativos (no descriptivos), explicaciones en los commits y ejemplos de uso en tests.
    \item \textbf{Control de versiones:} Uso de herramientas como Git para seguir cambios y facilitar la colaboración.
\end{itemize}

\subsection{Métricas de desarrollo}\label{subsec:metricas-de-desarrollo}

\begin{center}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Métrica}                             & \textbf{Descripción}                       \\
        \hline
        Densidad de comentarios                      & \% de comentarios respecto al código total \\
        Duplicidad de código                         & Código repetido                            \\
        Cobertura de pruebas                         & \% de código ejecutado durante pruebas     \\
        Complejidad ciclomática                      & Mide rutas lógicas (condiciones y bucles)  \\
        IMS (Índice de Madurez del código(Software)) & Evalúa la estabilidad de una release       \\
        \hline
    \end{tabular}
\end{center}

\begin{definicion}
    La fórmula para calcular el IMS es:
    \[
        IMS = \frac{M_T - (F_a + F_c + F_d)}{M_T}
    \]
    Donde:
    \begin{itemize}
        \item $M_T$: Número total de pruebas planificadas.
        \item $F_a$: Fallos críticos encontrados.
        \item $F_c$: Fallos menores encontrados.
        \item $F_d$: Fallos detectados en desarrollo.
    \end{itemize}
\end{definicion}

\subsection{Deuda técnica}\label{subsec:deuda-tecnica}

\begin{definicion}
    Según Martin Fowler, la deuda técnica es una metáfora financiera: tomar atajos en el diseño genera un \textquote{interés} que se paga con mayor esfuerzo futuro.
    Se puede:
    \begin{itemize}
        \item Seguir pagando intereses (mantener mal diseño).
        \item Pagar el principal (refactorizar y mejorar).
    \end{itemize}
\end{definicion}

Se clasifica según dos ejes:

\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        & \textbf{Temeraria}                              & \textbf{Prudente}                                    \\
        \hline
        \textbf{Deliberada}  & \textquote{No tenemos tiempo, entregamos ahora} & \textquote{Lo haremos rápido y mejoraremos después}  \\
        \hline
        \textbf{Inadvertida} & \textquote{¿Qué componentes tiene esto?}        & \textquote{Ahora sabemos cómo debería haberse hecho} \\
        \hline
    \end{tabular}
\end{center}
