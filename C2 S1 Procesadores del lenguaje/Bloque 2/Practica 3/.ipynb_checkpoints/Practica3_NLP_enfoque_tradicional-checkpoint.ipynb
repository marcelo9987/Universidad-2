{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "0oFc6yQWgalf"
   },
   "cell_type": "markdown",
   "source": [
    "# NLP - Enfoque tradicional\n",
    "Este notebook cubre varios conceptos del procesamiento del lenguaje natural (NLP) tradicional y utiliza diferentes bibliotecas como NLTK, SpaCy, TextBlob, Gensim y Scikit-learn para implementarlos y visualizarlos.\n"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqRKuoCug2yN",
    "outputId": "f040ecce-4355-4893-d798-e0c6746b7323",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T13:13:05.253238Z",
     "start_time": "2024-11-21T13:12:29.847896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install textblob\n",
    "!pip install gensim\n",
    "!pip install scikit-learn\n",
    "!pip install pyLDAvis\n",
    "!pip install language_tool_python"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n",
      "^C\n",
      "Requirement already satisfied: nltk in c:\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python312\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python312\\lib\\site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from spacy) (75.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\imarc\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\python312\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\python312\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python312\\lib\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk>=3.8->textblob) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcKGlXc1gali"
   },
   "source": [
    "## 1. Tokenización y Etiquetado POS (Análisis Léxico y Sintáctico - NLTK y SpaCy)\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teoría:**\\\n",
    "La **tokenización** es el proceso de dividir un texto en unidades más pequeñas llamadas \"tokens\". Esto es importante porque la mayoría de las tareas de NLP necesitan trabajar con palabras individuales o grupos pequeños de palabras.\\\n",
    "El **etiquetado POS (Part-of-Speech)** clasifica cada palabra en su categoría gramatical (como sustantivo, verbo, adjetivo, etc.), lo cual es crucial para entender la estructura gramatical de una oración."
   ],
   "metadata": {
    "id": "8uKuoxgKhtAZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementación con NLTK**\n",
    "\n"
   ],
   "metadata": {
    "id": "TKH5ACm4hxlZ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH6qsGw2galk",
    "outputId": "e0886ab6-b64e-490e-80a2-a1fdad378d9b",
    "ExecuteTime": {
     "end_time": "2024-11-21T13:12:19.012320Z",
     "start_time": "2024-11-21T13:12:16.518625Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Ejemplo de texto en inglés\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenización - Léxico\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Etiquetado POS con NLTK - Sintáctico\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"Etiquetas POS:\", pos_tags)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\n\u001B[0;32m      2\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt_tab\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'nltk'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge8Tt91Tgalm"
   },
   "source": [
    "**Visualización con Spacy**\\\n",
    "SpaCy proporciona una representación visual interactiva del **árbol de dependencias**, mostrando las **relaciones gramaticales** y las **etiquetas POS** *texto en cursiva*, lo que facilita la comprensión de la estructura de la oración."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''Necesitamos el modelo en español porque cada idioma tiene su propia estructura gramatical y reglas sintácticas.\n",
    "   Un modelo preentrenado en español como el de SpaCy puede realizar estas tareas de etiquetado gramatical y análisis sintáctico con precisión,\n",
    "   porque ha sido entrenado en los patrones lingüísticos específicos de este idioma.'''\n",
    "!pip install spacy\n",
    "!python -m spacy download es_core_web_sm\n",
    "#descarga el modelo español de spacy (terminal)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "r5Gb4IwFjm0E",
    "outputId": "18fd6273-739e-4f79-8094-d089dc6fd449",
    "ExecuteTime": {
     "end_time": "2024-11-18T17:36:33.979179Z",
     "start_time": "2024-11-18T17:36:29.288774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\universidad-2\\c2s1 procesadores del lenguaje\\ejercicios\\pythonproject\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[38;5;1m[x] No compatible package found for 'es_core_web_sm' (spaCy v3.8.2)\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "yycE3iEEgalm",
    "outputId": "b80b7f30-7003-4f2d-f98f-5fa9444d515e",
    "ExecuteTime": {
     "end_time": "2024-11-18T17:39:31.740917Z",
     "start_time": "2024-11-18T17:39:31.040120Z"
    }
   },
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Cargar el modelo en español\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = 'The quick brown fox jumps over the lazy dog.'\n",
    "\n",
    "# Procesar el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualizar el árbol de dependencias, incluyendo etiquetas POS.\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"dbdbc894d23d47a596617e69493238b7-0\" class=\"displacy\" width=\"950\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,2.0 350.0,2.0 350.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,52.0 345.0,52.0 345.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,154.0 L262,142.0 278,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-4\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M540.0,154.0 L548.0,142.0 532.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,52.0 845.0,52.0 845.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-6\" stroke-width=\"2px\" d=\"M770,152.0 C770,102.0 840.0,102.0 840.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,154.0 L762,142.0 778,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dbdbc894d23d47a596617e69493238b7-0-7\" stroke-width=\"2px\" d=\"M570,152.0 C570,2.0 850.0,2.0 850.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dbdbc894d23d47a596617e69493238b7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M850.0,154.0 L858.0,142.0 842.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk4PTycYgaln"
   },
   "source": [
    "## 2. Lematización y Reconocimiento de Entidades Nombradas (NER) (Análisis Léxico y Semántico - SpaCy)\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teoría:**\\\n",
    "La **lematización** reduce una palabra a su forma base o lema, ayudando a agrupar palabras con el mismo significado pero diferentes formas morfológicas.\\\n",
    "El **Reconocimiento de Entidades Nombradas (NER)** identifica entidades clave en el texto, como personas, lugares, organizaciones, etc., y es útil para extraer información relevante automáticamente."
   ],
   "metadata": {
    "id": "esWHgj3vlM6J"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementación y visualización con SpaCy.**"
   ],
   "metadata": {
    "id": "aoc9uAc3lPIT"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHUcLBYagaln",
    "outputId": "63532d06-ebe5-4539-ecf0-12a86c7b4414"
   },
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "!python -m spacy download es_core_news_sm\n",
    "# Cargar modelo en español\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = 'Apple fue fundada por Steve Jobs en California.'\n",
    "\n",
    "# Procesar el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lematización - Léxico\n",
    "print('Lemas:')\n",
    "for token in doc:\n",
    "    print(f'{token.text} -> {token.lemma_}')\n",
    "\n",
    "# Visualización de Entidades Nombradas - léxico/semántico\n",
    "displacy.render(doc, style='ent', jupyter=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "IuINyxEYlnq5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "CywoznsRsV4z"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJAX3owwlvQ-"
   },
   "source": [
    "## 3. Análisis de Sentimiento y Corrección Gramatical (Análisis Semántico - TextBlob)\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teoría:**\\\n",
    "El **análisis de sentimiento** mide la polaridad del texto (positivo, negativo, neutral) y es útil para comprender la opinión o actitud expresada en grandes volúmenes de texto.\\\n",
    "La **corrección gramatical** asegura la claridad y precisión del texto, especialmente en aplicaciones de escritura asistida."
   ],
   "metadata": {
    "id": "XFdhcGddl6m6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementación con TextBlob. - Analisis de sentimiento**"
   ],
   "metadata": {
    "id": "00NQB7M_l62A"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QSDCvxH9lvRA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "fb3016aa-f6f3-4ac5-a22c-27f54cb2901c"
   },
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Example text\n",
    "text = 'This product is absolutely wonderful.'\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentiment = blob.sentiment\n",
    "print(f'Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}')\n",
    "'''\n",
    "La frase tiene un sentimiento extremadamente positivo,\n",
    "por lo que la polaridad debería estar cerca de 1.0.\n",
    "Dado que la frase expresa una opinión subjetiva sobre el producto,\n",
    "la subjetividad también debería ser alta, cerca de 1.0\n",
    "'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementación con Language Tool. - Corrección gramatical**"
   ],
   "metadata": {
    "id": "8-Q5RKPgr6cp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install language_tool_python\n",
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "text_with_errors = \"She go to the market and buy apples.\"\n",
    "\n",
    "# Aplicar la corrección\n",
    "matches = tool.check(text_with_errors)\n",
    "corrected_text = language_tool_python.utils.correct(text_with_errors, matches)\n",
    "\n",
    "print(\"Original text:\", text_with_errors)\n",
    "print(\"Corrected text:\", corrected_text)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2v3H6STnvnP",
    "outputId": "1228031e-9c22-4305-e20d-441854e7fd2f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Bolsa de Palabras (BoW) y TF-IDF (Análisis Léxico - Gensim y Scikit-learn)\n",
    "----------------"
   ],
   "metadata": {
    "id": "zos_Hqp0sohD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Teoría:**\\\n",
    "La **Bolsa de Palabras (BoW)** representa un documento como un vector de frecuencias de palabras, ignorando el orden.\\\n",
    "El **TF-IDF** pondera la importancia de una palabra en un documento en relación con el conjunto de documentos, destacando palabras relevantes mientras se penalizan las comunes."
   ],
   "metadata": {
    "id": "PxaNA1xzsu1x"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacion con Gensim - BoW**"
   ],
   "metadata": {
    "id": "TmGH1o_Gs_dS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Gensim para Bolsa de Palabras (BoW)\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Documentos de ejemplo\n",
    "documents = ['El gato negro saltó sobre el sofá.', 'El perro ladró fuertemente en la casa.']\n",
    "\n",
    "# Tokenización\n",
    "texts = [[word.lower() for word in document.split()] for document in documents]\n",
    "\n",
    "# Creación del diccionario\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(\"Diccionario:\", dictionary.token2id)\n",
    "\n",
    "#Creación de la bolsa de palabras\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "print('Bolsa de Palabras:', corpus_bow)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z41ZO_oGtABS",
    "outputId": "5e48a711-9f45-4335-8001-806e88bda492"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "El diccionario representa el indice asignado a cada palabra.\\\n",
    "En la Bolsa de Palabras, tenemos un array por cada documento (frase en este caso). Cada array contiene una tupla (pares) por cada palabra. El primer numero de la tupla indica el indice de la palabra, el segundo cuantas veces se repite **en ese mismo** documento.\\\n",
    "\\\n",
    "Una representación más grafica de la bolsa de palabras:"
   ],
   "metadata": {
    "id": "yIpworsj763c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Convertir corpus_bow a una representación más visual utilizando pandas DataFrame\n",
    "# Creamos una matriz donde las columnas serán las palabras y las filas serán los documentos\n",
    "import pandas as pd\n",
    "data = []\n",
    "\n",
    "for bow in corpus_bow:\n",
    "    bow_dict = dict(bow)\n",
    "    data.append([bow_dict.get(dictionary.token2id[word], 0) for word in dictionary.token2id])\n",
    "\n",
    "# Crear un DataFrame con las palabras como columnas y \"doc 1\", \"doc 2\" como índices\n",
    "doc_names = [f\"doc {i+1}\" for i in range(len(corpus_bow))]\n",
    "df_bow = pd.DataFrame(data, columns=[dictionary[id] for id in range(len(dictionary))], index=doc_names)\n",
    "\n",
    "# Estilo de la tabla con líneas delimitadoras\n",
    "styled_df_bow = df_bow.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('border', '1px solid black')]},\n",
    "     {'selector': 'td', 'props': [('border', '1px solid black')]}]\n",
    ").set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Mostrar la tabla estilizada\n",
    "styled_df_bow"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "AOwUsSZCtFYl",
    "outputId": "f263d60b-9e51-4049-a300-347926736e5d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implementacion con Scikit-learn - TF-IDF**"
   ],
   "metadata": {
    "id": "1gIF5U10-P_H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Frecuencia de Término (TF):** Mide cuántas veces aparece una palabra específica en **un** documento.\n",
    "\n",
    "**Frecuencia Inversa de Documentos (IDF):** Mide la rareza de una palabra en el conjunto de documentos. Si una palabra aparece en muchos documentos, su IDF será **baja**, porque es **menos informativa** (palabras comunes como \"el\", \"y\", \"es\").\\\n",
    "**La ponderación TF-IDF**: se calcula multiplicando la TF de la palabra por su IDF. Esto pondera la frecuencia de la palabra según su rareza en el conjunto de documentos.\n",
    "\\\n",
    "**Casos de uso:** Clasificación de Textos, Búsqueda de Información, Filtrado de Palabras Relevantes"
   ],
   "metadata": {
    "id": "CC3crcJt_DZz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Scikit-learn para TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "documents = [\n",
    "    \"El gato negro saltó sobre el sofá. Luego, el gato descansó cómodamente en su lugar favorito. El gato siempre salta con agilidad.\",\n",
    "    \"El perro ladró fuertemente en la casa. Después, el perro salió a jugar en el jardín. El perro corre rápidamente.\",\n",
    "    \"El gato cazó un ratón en el jardín. Los gatos son excelentes cazadores, siempre al acecho. El gato volvió al sofá.\",\n",
    "    \"El perro dormía plácidamente en su cama. Cuando el perro se despertó, salió corriendo hacia el parque. El perro ama los paseos.\",\n",
    "    \"Los gatos son animales muy independientes. Les gusta dormir durante el día y cazar por la noche. El gato siempre vuelve a casa.\",\n",
    "    \"El perro es conocido por su lealtad hacia los humanos. El perro cuida la casa y siempre está alerta ante cualquier ruido extraño.\",\n",
    "    \"El gato se subió al árbol para escapar del perro. Los gatos son conocidos por su capacidad de trepar y escapar del peligro.\",\n",
    "    \"La computadora se apagó repentinamente mientras estaba ejecutando un programa importante. Después de reiniciarla, todos los archivos volvieron a estar accesibles.\"\n",
    "]\n",
    "\n",
    "# Crear y ajustar el vectorizador TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
    "\n",
    "# Obtener los nombres de las palabras (vocabulario)\n",
    "feature_names = vectorizer_tfidf.get_feature_names_out()\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame de pandas\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "\n",
    "# Añadir nombres de documentos (opcional)\n",
    "df_tfidf.index = [\n",
    "    '1 (gatos)',\n",
    "    '2 (perros)',\n",
    "    '3 (gatos)',\n",
    "    '4 (perros)',\n",
    "    '5 (gatos)',\n",
    "    '6 (perros)',\n",
    "    '7 (gatos)',\n",
    "    '8 (computadoras)'\n",
    "]\n",
    "# Mostrar la tabla\n",
    "print(df_tfidf)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrGWRG_Mvdac",
    "outputId": "24294e70-ec39-4e00-ff9c-46baaa7ea0a0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ejemplo de motor de búsqueda\n",
    "**Consulta:** El usuario ingresa una consulta, en este caso \"gato sofá\".\\\n",
    "**Transformación:** La consulta se transforma en su vector TF-IDF utilizando el mismo vectorizador que ya entrenaste con los documentos.\n",
    "**Similitud de Coseno:** Calculamos la similitud de coseno entre el vector TF-IDF de la consulta y los vectores de TF-IDF de los documentos.\\\n",
    "* Similitud de Coseno: mide cuán similares son dos vectores (en este caso, el vector de la consulta y los vectores de los documentos).\\\n",
    "* El valor varía entre 0 y 1, donde 1 significa documentos idénticos.\\\n",
    "\n",
    "**Resultado:** Mostramos las similitudes de coseno para cada documento y resaltamos cuál es el más relevante."
   ],
   "metadata": {
    "id": "W3b9IFC1FVsR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tu consulta\n",
    "query = \"gato sofá\"\n",
    "\n",
    "# Normalizar la consulta usando el mismo vectorizador TF-IDF que ya has creado\n",
    "query_tfidf = vectorizer_tfidf.transform([query])\n",
    "\n",
    "# Calcular la similitud de coseno entre la consulta y cada documento\n",
    "cosine_similarities = cosine_similarity(query_tfidf, X_tfidf).flatten()\n",
    "\n",
    "# Mostrar las similitudes\n",
    "print(\"Similitud de coseno entre la consulta y los documentos:\")\n",
    "for idx, sim in enumerate(cosine_similarities):\n",
    "    print(f\"Documento {idx + 1}: {sim}\")\n",
    "\n",
    "# Encontrar el documento más relevante\n",
    "most_similar_doc_index = np.argmax(cosine_similarities)\n",
    "print(f\"\\nEl documento más relevante para la consulta '{query}' es el Documento {most_similar_doc_index + 1}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LxjktLqA47c",
    "outputId": "9eabaf7a-503a-40dc-8d9c-6aa1029a16f4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Practica"
   ],
   "metadata": {
    "id": "B_nUR2B1G1nT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio: Exploración de la Normalización en Distintas Librerías\n",
    "\n",
    "### Introducción:\n",
    "\n",
    "La normalización del texto es un paso esencial en el procesamiento del lenguaje natural (NLP) que asegura que el texto esté limpio y estructurado para que pueda ser procesado por los algoritmos de NLP. En este ejercicio, aprenderás a aplicar diferentes técnicas de normalización del texto utilizando las librerías que hemos visto hasta ahora: **NLTK**, **SpaCy**, **TextBlob**, y **Gensim**.\n",
    "\n",
    "### Técnicas de Normalización:\n",
    "\n",
    "1. **Lowercasing**: Convertir todo el texto a minúsculas.\n",
    "2. **Eliminar puntuación**: Eliminar signos de puntuación innecesarios.\n",
    "3. **Eliminar números**: Remover los números que no aporten valor al análisis.\n",
    "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan información.\n",
    "5. **Lematización**: Reducir las palabras a su forma base.\n",
    "6. **Stemming (opcional)**: Aplicar stemming si la librería lo soporta.\n",
    "7. **Corrección ortográfica**: Corregir errores ortográficos en el texto.\n",
    "8. **Tokenización**: Dividir el texto en tokens.\n",
    "\n",
    "### Instrucciones:\n",
    "\n",
    "1. Busca en la documentación de cada librería (NLTK, SpaCy, TextBlob, Gensim) cómo puedes aplicar estas técnicas de normalización.\n",
    "2. Implementa las soluciones que encuentres para normalizar el texto en cada librería.\n",
    "3. Compara los resultados obtenidos en cada una:\n",
    " - ¿Qué diferencias encuentras entre las librerías?¿Cuáles son las fortalezas y limitaciones de cada una?\n",
    " - ¿Cómo afectó la normalización los resultados obtenidos en las diferentes técnicas de NLP (BoW, análisis de sentimiento, POS tagging, etc.)?\n",
    "4. Documenta lo implementado en cada técnica, el output que refleje los cambios y una comparativa antes y después del cambio.\n",
    "\n",
    "### Recursos:\n",
    "\n",
    "Aquí tienes enlaces a la documentación de cada librería para comenzar tu investigación:\n",
    "\n",
    "- [NLTK Documentation](https://www.nltk.org/)\n",
    "- [SpaCy Documentation](https://spacy.io/usage)\n",
    "- [TextBlob Documentation](https://textblob.readthedocs.io/en/dev/)\n",
    "- [Gensim Documentation](https://radimrehurek.com/gensim/)"
   ],
   "metadata": {
    "id": "GXAFX5jWG_yq"
   }
  }
 ]
}
